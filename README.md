# ğŸ§  xRAG: Token-Compressed, Quantized, Deployable RAG Pipeline for Local & Edge Systems

> **â€œCompact brains, sharp answers.â€**  
> A unified, efficient RAG pipeline optimized for edge & local deployments.

---

## ğŸ” What is xRAG?

**xRAG** (eXtreme Retrieval Augmented Generation) is a **token-compressed**, **quantized**, and **fully local** RAG system. Itâ€™s engineered for **low-latency**, **on-device** question answering and document retrievalâ€”perfect for applications that demand **speed, privacy, and portability**.

---

## ğŸ“š Inspired By 

This project draws from cutting-edge RAG and efficient model deployment research:

- **xRAG (2022)**: 1-token RAG with 17x compression using MLP bridges and I-token projection.


---

## âš¡ï¸ Problem Statement

Most RAG pipelines:
- Are **too bulky** for local use
- Depend on **cloud services**
- Struggle with **low-latency, high-efficiency** deployment

> **xRAG** aims to solve this by going fully local, compressing input, and minimizing memory & compute overhead.

---

## ğŸ—ï¸ Architecture Overview


![xrag drawio](https://github.com/user-attachments/assets/34093318-93e2-4b73-9b4f-4c74fa321c3d)



---

## ğŸ”¥ Features

- âœ… **Fully Local**: Works offline, on-device, no cloud required.
- ğŸ”» **Token Compression**: Fewer tokens, faster inference.
- âš¡ **Quantized Models**: Lightweight, edge-ready transformers.
- ğŸ§© **Modular Components**: Swap retrievers, bridges, and generators.
- ğŸ“š **Document-Aware**: Pulls relevant context before answering.
- ğŸ§  **Context Memory**: Maintains logical conversation threads.

---


## ğŸ” Use Cases

- ğŸ§‘â€ğŸ« AI Tutors (offline, classroom-ready)
- ğŸ” Private assistants (no cloud dependencies)
- ğŸ§­ Search across personal documents
- ğŸ§  Lightweight research copilots



